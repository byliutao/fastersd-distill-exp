{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to get repository contents: HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /api/datasets/zhwang/HPDv2 (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x7f1163f8c460>, 'Connection to huggingface.co timed out. (connect timeout=None)'))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/liutao/miniconda3/envs/instaflow/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/liutao/miniconda3/envs/instaflow/lib/python3.10/site-packages/diffusers/utils/outputs.py:63: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "/home/liutao/miniconda3/envs/instaflow/lib/python3.10/site-packages/diffusers/utils/outputs.py:63: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "2024-03-03 19:54:31.539871: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-03 19:54:31.539893: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-03 19:54:31.540483: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-03 19:54:31.996727: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/liutao/miniconda3/envs/instaflow/lib/python3.10/site-packages/diffusers/utils/outputs.py:63: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import hpsv2\n",
    "import torch\n",
    "import json\n",
    "import clip\n",
    "from PIL import Image\n",
    "import os\n",
    "from diffusers import DiffusionPipeline\n",
    "from diffusers import StableDiffusionPipeline, EulerDiscreteScheduler\n",
    "import torch\n",
    "from pipeline_rf import RectifiedFlowPipeline\n",
    "import random\n",
    "from diffusers import AutoPipelineForText2Image\n",
    "import json\n",
    "import generate_swift as gs\n",
    "from generate import generate_single_image, load_model\n",
    "from dataclasses import dataclass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class TestConfig:\n",
    "    device = \"cuda:1\"\n",
    "    ours_steps = 8\n",
    "    ours_hpsv2_path = \"/data/liutao/data/ours_36k_8i_hpsv2\"\n",
    "    ours_coco_path = \"/data/liutao/data/ours_36k_8s_coco\"\n",
    "    clip_model_id = \"ViT-L/14@336px\"\n",
    "    ours_model_id = \"/data/20231212/SwiftBrush_reproduce_se_parallel/checkpoints_20240228/vsd_global_step36000_8nis.pth\"\n",
    "    ours_base_path = \"/data/\"\n",
    "    coco_caption_path = \"/data/dataset/coco2014-val/annotations/captions_val2014.json\"\n",
    "    caption_num = 30000\n",
    "    seed = 2024\n",
    "config = TestConfig()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_model, clip_preprocess = clip.load(config.clip_model_id)\n",
    "clip_model = clip_model.to(config.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading student unet checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/liutao/miniconda3/envs/instaflow/lib/python3.10/site-packages/diffusers/utils/outputs.py:63: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "vae, tokenizer, text_encoder, unet, scheduler, alphas = load_model(config.ours_base_path, config.ours_model_id, config.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## clip score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clip_score(image, text):\n",
    "    # Load the pre-trained CLIP model and the image\n",
    "\n",
    "    # Preprocess the image and tokenize the text\n",
    "    image_input = clip_preprocess(image).unsqueeze(0)\n",
    "    text_input = clip.tokenize([text], truncate=True)\n",
    "    \n",
    "    # Move the inputs to GPU if available\n",
    "    image_input = image_input.to(config.device)\n",
    "    text_input = text_input.to(config.device)\n",
    "    \n",
    "    # Generate embeddings for the image and text\n",
    "    with torch.no_grad():\n",
    "        image_features = clip_model.encode_image(image_input)\n",
    "        text_features = clip_model.encode_text(text_input)\n",
    "    \n",
    "    # Normalize the features\n",
    "    image_features = image_features / image_features.norm(dim=-1, keepdim=True)\n",
    "    text_features = text_features / text_features.norm(dim=-1, keepdim=True)\n",
    "    \n",
    "    # Calculate the cosine similarity to get the CLIP score\n",
    "    clip_score = torch.matmul(image_features, text_features.T).item()\n",
    "    \n",
    "    return clip_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load coco30k_caption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000 A bicycle replica with a clock as the front wheel. A black Honda motorcycle parked in front of a garage.\n"
     ]
    }
   ],
   "source": [
    "coco_f = open(config.coco_caption_path)\n",
    "coco_annotations = json.load(coco_f)\n",
    "captions = []\n",
    "for annotation in coco_annotations['annotations']:\n",
    "    caption = annotation['caption']\n",
    "    captions.append(caption)\n",
    "coco_f.close()\n",
    "random.seed(config.seed)\n",
    "captions_30k = random.choices(captions, k=config.caption_num)\n",
    "print(len(captions_30k),captions[0],captions[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current num: 1000 current avg clip score: 0.2615880126953125\n",
      "current num: 2000 current avg clip score: 0.2610256958007813\n",
      "current num: 3000 current avg clip score: 0.260946533203125\n",
      "current num: 4000 current avg clip score: 0.26053231811523436\n",
      "current num: 5000 current avg clip score: 0.2607731689453125\n",
      "current num: 6000 current avg clip score: 0.2605646769205729\n",
      "current num: 7000 current avg clip score: 0.26062793840680804\n",
      "current num: 8000 current avg clip score: 0.26105057525634767\n",
      "current num: 9000 current avg clip score: 0.2608954467773438\n",
      "current num: 10000 current avg clip score: 0.2608013977050781\n",
      "current num: 11000 current avg clip score: 0.2607430586381392\n",
      "current num: 12000 current avg clip score: 0.2606460622151693\n",
      "current num: 13000 current avg clip score: 0.2606663771409255\n",
      "current num: 14000 current avg clip score: 0.26059676252092634\n",
      "current num: 15000 current avg clip score: 0.26063055419921877\n",
      "current num: 16000 current avg clip score: 0.26057498550415037\n",
      "current num: 17000 current avg clip score: 0.26064408964269303\n",
      "current num: 18000 current avg clip score: 0.2606989305284288\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "total_score = 0\n",
    "for case_number, prompt in enumerate(captions_30k):\n",
    "    image = generate_single_image(network=(vae, tokenizer, text_encoder, unet, scheduler),prompt=prompt,seed=2024,num_inference_steps=ours_steps)\n",
    "    score = get_clip_score(image, prompt)\n",
    "    save_name = str(count)+\".jpg\"\n",
    "    image.save(os.path.join(config.ours_coco_path,save_name))\n",
    "    total_score += score\n",
    "    count += 1\n",
    "    if count % 1000 == 0:\n",
    "        print(\"current num:\",count,\"current avg clip score:\",total_score/count)\n",
    "print(f\"AVG CLIP Score: {total_score/count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hpsv2 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_prompts = hpsv2.benchmark_prompts('all') \n",
    "for style, prompts in all_prompts.items():\n",
    "    for idx, prompt in enumerate(prompts):\n",
    "        image = generate_single_image(network=(vae, tokenizer, text_encoder, unet, scheduler),prompt=prompt,seed=2024,num_inference_steps=ours_steps)\n",
    "        image.save(os.path.join(config.ours_hpsv2_path, style, f\"{idx:05d}.jpg\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hpsv2.evaluate(config.ours_hpsv2_path) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "instaflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
